Thor Olesen is a CS PhD at UCLA under professor Jens Palsberg doing research in Programming Languages, Software Systems, and Quantum Computing. 
In particular, he is focused on designing and implementing high-level quantum programming languages, driving better static program analysis using machine learning, and building better software engineering tools. 
In the past, Thor worked over two years as a senior software engineer at The Org, where he built distributed recommender systems and data engineering pipelines. 

Thor's past research interests have been focused on enabling robots to perceive, think, and act on a human level when solving diverse tasks from few examples across changing environments. 
To this end, his work has included model-free deep reinforcement learning algorithms for learning visual perception and control in video games (e.g. DQN), and model-based reinforcement learning that enables planning by learning a sample-efficient model of the world. 
Thor received an MSc in Computer Science from the IT University, Copenhagen in 2020, where he was advised by Sebastian Risi, and he received a BSc in Software Development from the IT University in 2017 and a BSc (double degree) in Computer Science from the University of Copenhagen in 2021. 
In Fall 2018, he also studied a semester abroad at UC Berkeley where he took courses in Artificial Intelligence, Data Science, and Statistics, and got a letter of recommendation from Pieter Abbeel. 
He has been a teaching assistant more than 20 times and has worked as an assistant lecturer in Advanced Machine Learning and TA in Linear Algebra, Probability, and Artificial Intelligence. 

He has a specialization in Advanced Machine Learning and finished his master's with distinction before publishing his thesis results to a peer-reviewed conference in 2020. 
He published his work as a first author to the 24th International Conference on Applications of Evolutionary Computation as part of EvoStar 2021. 
In his work, he showed how to do evolutionary planning in latent space. Namely, he showed how to learn a world model of the 2D car racing environment in the Open AI Gym that enables planning. 
This entailed using a variational auto encoder to learn a latent representation of visual frame observations and using a mixture density recurrent neural network to learn a latent dynamics model to predict future states and rewards in latent space (simulation). 
The planning agent was built using a simple evolutionary algorithm, random mutation hill climbing (rhea), that seamlessly searches for a good driving policy in the continuous action space of the environment. 
It does so by mutating a randomly picked sequence of driving actions in a local policy subspace and it picks a plan that maximizes the expected total reward up to a certain horizon in the simulation of the world model. 
Ultimately, Thor showed that it is possible to outcompete popular model-free approaches by learning a sample-efficient model of the environment that generalizes across random driving tracks and can be used to simulate continous driving trajectories online with a simple evolutionary algorithm whose simulated policy also results in great driving behaviour in the real environment. 

Today, his industry experience has made him more interested in software engineering, programming languages, and computer systems, transitioning away from artificial intelligence and data. 
That is, how can we design and build more productive developer tools and programming languages to solve tomorrow's problems (e.g., a universal high-level quantum language). 
